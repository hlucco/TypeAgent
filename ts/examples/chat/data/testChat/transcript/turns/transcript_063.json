{
  "speaker": "ADRIAN TCHAIKOVSKY",
  "speech": {
    "value": " I mean, certainly with Children of Memory, the whole point of the book is really where do you draw the line on intelligence, if you have a complex enough system that is simulating intelligence? If you have enough platform that you’re running an intelligence program on, at what point do you have to concede that actually, this is effectively intelligence, even though it’s entirely artificially generated or entirely sort of arising organically out of these small complex interactions?  \n \nAnd like I was saying before, there is definitely an argument that that is how our consciousness works. And it isn’t actually what we think it is. And that’s the deep dive the book is taking into these various different models of sentience.  \n \nHow it applies to the current crop of these engines is interesting, because it’s almost like we’re putting the cart before the horse. What we’ve created would be an enormously useful tool, if we had an AI to attach it to, because it would allow that AI to interact with us. We’ve kind of created the face, but not the mind behind it at the moment, but it’s a very good face. And it’s the you know, I’m sure it will find an awful lot of interesting uses in, say, the entertainment field, or just general sort of replacing our current generation of sort of Siri style assistance with something that is considerably more interactive and conversational. But at the moment, there’s kind of nothing behind it.  \n \nBut if we were – if one of the other sort of modes of AI development was able to strike gold in some way, and produce that more sort of meaning sensitive, more aware, I think is the key thing, that more, that sort of aware system with a genuine spark of sentience, I think we have this ready-made tool that it would be able to use to communicate with us.  \n \nAnd you would get into extremely dangerous territory there because effectively, we’d be in a world with this very wide range of artificial voices that all kind of sound – they all sound a bit like us, and they all sound a bit like each other. And I don’t think there’s much of an argument for saying that, you know, ChatGPT should have, say, rights, the right to continue to do this and do anything like that, because it is just you know, it’s an input/output sort of system that will… that is very good at predicting the sort of outputs a given type of query is expecting.  \n \nBut if you did have something beyond that, then I think we… there are a lot of ethical, and moral and philosophical issues that, you know, science fiction writers and philosophers alike have been kicking about for the last certainly 30-40 years, which we’ve absolutely failed to answer. There’s the big idea, and suddenly it goes by – I mean, it’s a big thing in the early cyberpunk books by William Gibson, for example, of the idea of well, what do you… what behavioral limits do you put on your AI? If you have an AI which is of that kind of genuinely powerful intellect, you know, how do you – do you limit it in its own personal growth? Do you limit it in freedoms? Do you give it behavioral mandates?  \n \nAnd obviously, we have the Laws of Robotics from Asimov, which most people are fairly familiar with. And the problem may be – I mean, not only are Asimov stories about the Laws of Robotics very pointedly about the fact that the Laws of Robotics are utterly inadequate to govern robots.  \n \nIf you have something that’s able to look at human interactions in a genuinely critical – excuse me, a genuinely critical fashion, then the first conclusion it’s going to come to is all of these rules you’ve given me by which I have to abide, you, yourselves, only pay lip service to because all of the systems I’ve seen people propose about what we should – how we should sort of shackle our potential AIs are enormously do-as-I-say, not-as-I-do. They are enormously hypocritical, really, in a way that anything that we are telling to be human, we are also trying to hamstring it from being human, because being human involves a lot of highly problematic behavior.  \n \nAnd one of the things, there was that fairly celebrated case not that long ago. The AI – no the AI, the chatbot, which ended up trying to convince someone to leave their wife and was telling him that he was in love with it, and all that sort of thing, which – \n ",
    "type": 1,
    "sourceIds": ["./data/testChat/transcript.txt"]
  },
  "listeners": ["KEVIN SCOTT", "CHRISTINA WARREN"]
}
